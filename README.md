# Sorting University Records
## About
I was given two .csv files containing mock university records. I first created bash scripts to download, sort and verify the data. I also removed duplicated rows. Secondly, I expressed the data in a relational model and listed the minimal set of functional dependencies.

Now the data was analysed, I normalised the records to third normal form. I then wrote the corresponding SQL statements to import and normalise the .csv files in SQLite. I then wrote complex SQL queries to select data from the normalised tables.

I documented the entire process using LaTeX. I had separate .tex files for each section and collected them into a main .tex files using \input{}. This complied to a professional .pdf file containing the report.

## Script usage
